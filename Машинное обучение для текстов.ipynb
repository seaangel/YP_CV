{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "тексты.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDmj43JcW_F6"
      },
      "source": [
        "# Проект для «Викишоп» с Bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNCxBDkjW_F7"
      },
      "source": [
        "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
        "\n",
        "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
        "\n",
        "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
        "\n",
        "**Инструкция по выполнению проекта**\n",
        "\n",
        "1. Загрузите и подготовьте данные.\n",
        "2. Обучите разные модели. \n",
        "3. Сделайте выводы.\n",
        "\n",
        "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
        "\n",
        "**Описание данных**\n",
        "\n",
        "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHx1bAFKW_F8"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import warnings\n",
        "\n",
        "from tqdm import notebook\n",
        "import transformers as ppb # pytorch transformers\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import f1_score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZm4MarLW_F-"
      },
      "source": [
        "warnings.filterwarnings('ignore',category=Warning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-4_689NW_F_"
      },
      "source": [
        "## Подготовка"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4cG7_HTW_F_"
      },
      "source": [
        "Тут попытаемся прочитать файл, он у меня локально"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caF-30nSW_GA"
      },
      "source": [
        "try:\n",
        "    #df_text = pd.read_csv('https://code.s3.yandex.net//toxic_comments.csv')\n",
        "    df_text = pd.read_csv('C:/ya/toxic_comments.csv')\n",
        "except:\n",
        "    df_text = pd.read_csv('/datasets/toxic_comments.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otDdm0XbW_GB"
      },
      "source": [
        "Посмотрим на данные"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUCDxlMUW_GB",
        "outputId": "470235a0-b6cc-4275-a070-238331474c08"
      },
      "source": [
        "df_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159566</th>\n",
              "      <td>\":::::And for the second time of asking, when ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159567</th>\n",
              "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159568</th>\n",
              "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159569</th>\n",
              "      <td>And it looks like it was actually you who put ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159570</th>\n",
              "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>159571 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text  toxic\n",
              "0       Explanation\\nWhy the edits made under my usern...      0\n",
              "1       D'aww! He matches this background colour I'm s...      0\n",
              "2       Hey man, I'm really not trying to edit war. It...      0\n",
              "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
              "4       You, sir, are my hero. Any chance you remember...      0\n",
              "...                                                   ...    ...\n",
              "159566  \":::::And for the second time of asking, when ...      0\n",
              "159567  You should be ashamed of yourself \\n\\nThat is ...      0\n",
              "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
              "159569  And it looks like it was actually you who put ...      0\n",
              "159570  \"\\nAnd ... I really don't think you understand...      0\n",
              "\n",
              "[159571 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "By2j4u-iW_GC",
        "outputId": "634143d1-3499-406e-b6f6-df44e48cd652"
      },
      "source": [
        "df_text['toxic'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    143346\n",
              "1     16225\n",
              "Name: toxic, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bxFtSnUW_GD"
      },
      "source": [
        "У нас много лишних символов, но так как будем использовать Bert, то можно их не удалять. Модель должна справиться"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZFRZf30W_GE"
      },
      "source": [
        "## Подготовка\n",
        "\n",
        "Загрузка предобученной модели/токенизатора "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg8bMi3cW_GF",
        "outputId": "c83729c7-57aa-44bd-a709-8de1bfa09de9"
      },
      "source": [
        "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model = model_class.from_pretrained(pretrained_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLJlRWmAW_GG"
      },
      "source": [
        "#Ограничим в 500 строк, иначе зависает\n",
        "features = df_text['text'][:500]\n",
        "target = df_text['toxic'][:500]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuiLrYxmW_GH"
      },
      "source": [
        "Посмотрим размер"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unq-9qcwW_GH",
        "outputId": "3b801c3d-128f-414a-c47a-8166e81a1c9d"
      },
      "source": [
        "target.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    450\n",
              "1     50\n",
              "Name: toxic, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ1NAKsCW_GI"
      },
      "source": [
        "Преобразуем каждое предложение в список идентификаторов (токенов). \n",
        "Возьмем 512, так как этор максимальная длинна, которую может принять Bert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "722efafd3ff443c5ba68bb641f178b83"
          ]
        },
        "id": "Eo53qIm8W_GJ",
        "outputId": "3b924738-f20a-4814-c870-fd3d9b6a7349"
      },
      "source": [
        "notebook.tqdm.pandas()\n",
        "tokenized = features.progress_apply((lambda x: tokenizer.encode(x[:512], add_special_tokens=True)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "722efafd3ff443c5ba68bb641f178b83",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=500.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_Ip49IMW_GJ"
      },
      "source": [
        "Применим метод padding, чтобы после токенизации длины исходных текстов в корпусе были равными, при таком условии будет работать модель BERT. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Suw5MTFjW_GK"
      },
      "source": [
        "padded = np.array([i + [0]*(512 - len(i)) for i in tokenized.values])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD1yq8hsW_GK"
      },
      "source": [
        "Создадим маску для важных токенов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B7FXdD5W_GL",
        "outputId": "9b66bcb6-f028-46bf-b974-076af1671ef2"
      },
      "source": [
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "\n",
        "padded.shape,attention_mask.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((500, 512), (500, 512))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjxO9AqgW_GL"
      },
      "source": [
        "Преобразуем тексты в векторных формат"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "f1b7072d34e3409eb6697ef63afeb7be"
          ]
        },
        "id": "WjCPj4OGW_GM",
        "outputId": "cff84071-d794-490e-a008-f548dd27c379"
      },
      "source": [
        "batch_size = 10\n",
        "embeddings = []\n",
        "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
        "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
        "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
        "        \n",
        "        embeddings.append(batch_embeddings[0][:,0,:].numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1b7072d34e3409eb6697ef63afeb7be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPFJVzhhW_GM"
      },
      "source": [
        "Соберём все эмбеддинги в матрицу признаков вызовов функции concatenate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGKWhHUNW_GN",
        "outputId": "1185d87a-205b-476e-b417-f6ab7b0db95f"
      },
      "source": [
        "features_embeddings = np.concatenate(embeddings)\n",
        "features_embeddings.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4WljLZJW_GO"
      },
      "source": [
        "Разделим выборку"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZ0KuRinW_GO"
      },
      "source": [
        "features_embeddings_train,features_embeddings_test,target_embeddings_train,target_embeddings_test = train_test_split(features_embeddings,target,test_size=0.2,random_state=0,stratify=target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXhDcdfSW_GP"
      },
      "source": [
        "## Обучение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4oetJBhW_GP"
      },
      "source": [
        "Подберем лучшие парметры"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymWn4XDzW_GP",
        "outputId": "a38d61a2-8207-4e6b-fb55-08ee91ecd6a5"
      },
      "source": [
        "parameters = {'C': np.linspace(0.0001, 100, 20)}\n",
        "grid_search = GridSearchCV(LogisticRegression(), parameters)\n",
        "grid_search.fit(features_embeddings_train, target_embeddings_train)\n",
        "\n",
        "print('best parameters: ', grid_search.best_params_)\n",
        "print('best scrores: ', grid_search.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best parameters:  {'C': 5.263252631578947}\n",
            "best scrores:  0.9450000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mr7lNbbW_GQ",
        "outputId": "7044412b-729c-4ecf-d186-8fab898e5d1a"
      },
      "source": [
        "lr= LogisticRegression(C = 5.263252631578947)\n",
        "lr.fit(features_embeddings_train,target_embeddings_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=5.263252631578947)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN7w9R19W_GQ"
      },
      "source": [
        "predictions = lr.predict(features_embeddings_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9pFM7z3W_GR",
        "outputId": "57023cb7-508e-4ec8-e61d-1388d0624a4c"
      },
      "source": [
        "print('Метрика f1 модели DistilBertModel {:.2f}'.format(f1_score(target_embeddings_test, predictions)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Метрика f1 модели DistilBertModel 0.75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhiSQzVNW_GR"
      },
      "source": [
        "## Выводы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FElH4B3rW_GS"
      },
      "source": [
        "У нас получилось создать инструмент, который поможет магазину выяснять в автоматическом режиме, что надо отправлять на модерацию, а что нет.\n",
        "\n",
        "Метрика f1 у нас получилась равно 0.75. При этом было использовано всего 500 строк из Датасета, скорее всего с более мощной машиной удастся достичь лучших результатов"
      ]
    }
  ]
}